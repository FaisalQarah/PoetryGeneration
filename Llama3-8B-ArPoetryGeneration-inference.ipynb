{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae9ce7-072c-462f-93b3-eee8f55f3d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d3566-01b8-46c9-a7b7-e48032975467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b05ca3e-dcba-49c9-92eb-8dd7b5fdb72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2090907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "492624"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newLink</th>\n",
       "      <th>count</th>\n",
       "      <th>input</th>\n",
       "      <th>outputPoem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://poetry.dctabudhabi.ae/#/poems/1-%D8%AE...</td>\n",
       "      <td>5</td>\n",
       "      <td>خليلي لا تستعجلا أن تزودا # وأن تجمعا شملي وتن...</td>\n",
       "      <td>خليلي لا تستعجلا أن تزودا # وأن تجمعا شملي وتن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://poetry.dctabudhabi.ae/#/poems/1-%D8%AE...</td>\n",
       "      <td>5</td>\n",
       "      <td>لعمرك ما نفس بجد رشيدة # تؤامرني سرا لأصرم مرثدا</td>\n",
       "      <td>وإن ظهرت منه قوارص جمة # وأفرع في لومي مرارا و...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://poetry.dctabudhabi.ae/#/poems/1-%D8%AE...</td>\n",
       "      <td>3</td>\n",
       "      <td>وإن صرحت كحل وهبت عرية # من الريح لم تترك لذي ...</td>\n",
       "      <td>صبرت على وطء الموالي وحطمهم # إذا ضن ذو القربى...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://poetry.dctabudhabi.ae/#/poems/10-%D9%8...</td>\n",
       "      <td>5</td>\n",
       "      <td>هل لا يهيج شوقك الطلل # أم لا يفرط شيخك الغزل</td>\n",
       "      <td>أم ذا القطين أصاب مقتله # منه وخانوه إذا احتمل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://poetry.dctabudhabi.ae/#/poems/10-%D9%8...</td>\n",
       "      <td>5</td>\n",
       "      <td>تامت فؤادك يوم بينهم # عند التفرق ظبية عطل</td>\n",
       "      <td>شنفت إلى رشأ ترببه # ولها بذات الحاذ معتزل\\nظل...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             newLink  count   \n",
       "0  https://poetry.dctabudhabi.ae/#/poems/1-%D8%AE...      5  \\\n",
       "1  https://poetry.dctabudhabi.ae/#/poems/1-%D8%AE...      5   \n",
       "2  https://poetry.dctabudhabi.ae/#/poems/1-%D8%AE...      3   \n",
       "3  https://poetry.dctabudhabi.ae/#/poems/10-%D9%8...      5   \n",
       "4  https://poetry.dctabudhabi.ae/#/poems/10-%D9%8...      5   \n",
       "\n",
       "                                               input   \n",
       "0  خليلي لا تستعجلا أن تزودا # وأن تجمعا شملي وتن...  \\\n",
       "1   لعمرك ما نفس بجد رشيدة # تؤامرني سرا لأصرم مرثدا   \n",
       "2  وإن صرحت كحل وهبت عرية # من الريح لم تترك لذي ...   \n",
       "3      هل لا يهيج شوقك الطلل # أم لا يفرط شيخك الغزل   \n",
       "4         تامت فؤادك يوم بينهم # عند التفرق ظبية عطل   \n",
       "\n",
       "                                          outputPoem  \n",
       "0  خليلي لا تستعجلا أن تزودا # وأن تجمعا شملي وتن...  \n",
       "1  وإن ظهرت منه قوارص جمة # وأفرع في لومي مرارا و...  \n",
       "2  صبرت على وطء الموالي وحطمهم # إذا ضن ذو القربى...  \n",
       "3  أم ذا القطين أصاب مقتله # منه وخانوه إذا احتمل...  \n",
       "4  شنفت إلى رشأ ترببه # ولها بذات الحاذ معتزل\\nظل...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "463638"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('AraPoems_Dataset.csv')\n",
    "df.fillna('', inplace=True)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "\n",
    "df['group_count'] = df.groupby('link').cumcount()\n",
    "\n",
    "df['newLink'] = df.apply(lambda x: f\"{x['link']}_{x['group_count'] // 5:02d}\", axis=1)\n",
    "\n",
    "\n",
    "def process_group(group):\n",
    "    count = group['first_hemistich'].count()\n",
    "    full_sentences = (group['first_hemistich'] + ' # ' + group['second_hemistich']).tolist()\n",
    "    first_line = full_sentences[0] if len(full_sentences) > 0 else ''\n",
    "    compiled_text = '\\n'.join(full_sentences[1:]) if len(full_sentences) > 1 else ''\n",
    "    return pd.Series({\n",
    "        'count': count,\n",
    "        'input': first_line,\n",
    "        'outputPoem': compiled_text\n",
    "    })\n",
    "    \n",
    "\n",
    "dfc = df.groupby('newLink').apply(process_group).reset_index()\n",
    "\n",
    "# dfc = df.groupby('link')['first_hemistich'].count().reset_index(name='count')\n",
    "dfc.fillna('', inplace=True)\n",
    "display(len(dfc))\n",
    "display(dfc[:5])\n",
    "# dfc = dfc[dfc['link'] != '']\n",
    "# display(len(dfc))\n",
    "dfc = dfc[dfc['count'] > 1]\n",
    "display(len(dfc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20127cc8-3b6c-4de7-9e48-242b88983042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401a137-ad59-4e4a-bff9-fe9aac65d328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922fb09a-6451-4ccd-b2bd-07e19889273f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d25f5e-743e-458d-9528-5c450606812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 06:03:13.663835: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-11 06:03:13.683424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-11 06:03:13.964504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/463638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6287304b18984ec88f94cd163845a200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: أيام ريب الدهر عني # ساكت والعيش ناطق\n",
      "Output: \n",
      "\n",
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: أيام ريب الدهر عني # ساكت والعيش ناطق\n",
      "Output:  # \n",
      "لقد تمنيتك يا منى # لشبيبتي وأصابتي\n",
      "فإذا غدوت فلا تكن # مني لقلبي حياتي\n",
      "إن لم تجد لي منيتي # فأنا مني منيتي\n",
      "فإذا صرت منيتي # فليس لي منيتي  #  #  #  #  #  #  #  # \n",
      "\n",
      "the original output\n",
      "يا سادة نكثوا العهود # على النوى ونسوا المواثق\n",
      "الحزن معتقل لدي # ببعدكم والصبر أبق\n",
      "أنا من بلوتم فعله # وخلائقي تلك الخلائق\n",
      "فكما علمتم في معا # تبة الأحبة لا أضايق\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    # instructions = examples[\"instruction\"]\n",
    "    # instructions = f'generate {} verses in Arabic using the following verse as a starting point'\n",
    "    counts = examples[\"count\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"outputPoem\"]\n",
    "    texts = []\n",
    "    # for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "    for count, input, output in zip(counts, inputs, outputs):\n",
    "        instructions = f'generate {count} verses in Arabic using the following verse as a starting point'\n",
    "        text = f\"Instruction: {instructions}\\nInput: {input}\\nOutput: {output}\"\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset = Dataset.from_pandas(dfc)\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.01)\n",
    "\n",
    "# display(dataset)\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained('checkpoint/')\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "instructions = f'generate {test_dataset[i][\"count\"]} verses in Arabic using the following verse as a starting point'\n",
    "input = test_dataset[i][\"input\"]\n",
    "output = '' \n",
    "text = f\"Instruction: {instructions}\\nInput: {input}\\nOutput: {output}\"\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "result = pipe(text)  #, temperature=0.7\n",
    "print(text)\n",
    "print()\n",
    "print(result[0]['generated_text'])\n",
    "print()\n",
    "print(f'the original output\\n{test_dataset[i][\"outputPoem\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a5ce8-c584-46a3-b4e2-0f18db67e582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9c5849b-20f9-437d-a13e-3b619fa00373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: فلا تعجلن وانظر بأرضك فارسا # يهز ردينيا وأبيض صارما\n",
      "Output: \n",
      "\n",
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: فلا تعجلن وانظر بأرضك فارسا # يهز ردينيا وأبيض صارما\n",
      "Output:  وعد عن الحداثة إنها أعمى # فما في الحقيقة من رونق زاهي\n",
      "وأرأف بالشباب واعلم أن هذا # شؤون الحياة من العيش الرقاق\n",
      "وأنك فان عاجلا أو قريبا # وأعلم أن حياتك ذات نهاق\n",
      "و\n",
      "\n",
      "the original output\n",
      "له كل يوم غارة عرفت له # إذا قادها للموت جردا سواهما\n",
      "وعبد بني برشا تركنا مجدلا # غداة ثوى بين الفوارس كازما\n",
      "تناولته فاختل سيفي ذبابه # شراسيفه العليا وجد المعاصما\n",
      "وأنت قريب قد رأيت مكانه # تنادي شتيرا يوم ذاك وعاصما\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "instructions = f'generate {test_dataset[i][\"count\"]} verses in Arabic using the following verse as a starting point'\n",
    "input = test_dataset[i][\"input\"]\n",
    "output = '' \n",
    "text = f\"Instruction: {instructions}\\nInput: {input}\\nOutput: {output}\"\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "result = pipe(text)  #, temperature=0.7\n",
    "print(text)\n",
    "print()\n",
    "print(result[0]['generated_text'])\n",
    "print()\n",
    "print(f'the original output\\n{test_dataset[i][\"outputPoem\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f286f9-fe54-4ae9-8e36-dd97cc3c72e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b207dac3-5b08-4c11-b16c-d9e52886d475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: صديق يداري الحزن عنك مماذق # ودمع يغب العين فيك منافق\n",
      "Output: \n",
      "\n",
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: صديق يداري الحزن عنك مماذق # ودمع يغب العين فيك منافق\n",
      "Output:  وإن كنت قد أصبحت في حيرة # من الحب لا تأخذك الأشواق\n",
      "فلا تجزعن منك الحوادث إنما # الحوادث في حياة الفتى أوهام\n",
      "وإن كنت قد عرفت منك الحب فانظر # إلى العين منك كيف هي واه\n",
      "وأدرك بفهم\n",
      "\n",
      "the original output\n",
      "وقلب إذا عانى الأسى طلب الأسى # لراحته من رق ودك أبق\n",
      "بكى القاطنون الظاعنون وقوض ال # حلول وصاحت بالفراق النواعق\n",
      "ولكنني بالأمس لم تسر ناقة # بمختلس مني ولم يحد سائق\n",
      "سلا عنه في أي المفاوز فاتني # وطرفي له راع وطرفي سابق\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "\n",
    "instructions = f'generate {test_dataset[i][\"count\"]} verses in Arabic using the following verse as a starting point'\n",
    "input = test_dataset[i][\"input\"]\n",
    "output = '' \n",
    "text = f\"Instruction: {instructions}\\nInput: {input}\\nOutput: {output}\"\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "result = pipe(text)  #, temperature=0.7\n",
    "print(text)\n",
    "print()\n",
    "print(result[0]['generated_text'])\n",
    "print()\n",
    "print(f'the original output\\n{test_dataset[i][\"outputPoem\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d32f69-c7bc-4659-b1f0-461887267354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: وثارت عليه الروح تطلب ثارها # كما هز قرم في الجلاد مهندا\n",
      "Output: \n",
      "\n",
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: وثارت عليه الروح تطلب ثارها # كما هز قرم في الجلاد مهندا\n",
      "Output:  ولو أنني كنت المريد لم يكن # لتعرفه إلا المريد المريد\n",
      "وإن كنت في عين الوجود منية # فإنك لا عين ولا وجودا\n",
      "فلا تطلبن مني سواه فإنه # إذا قيل من أين الرجاء فما أرى\n",
      "وأنت بلا ذنب أتيتك مقلدا\n",
      "\n",
      "the original output\n",
      "فبات بحمى صدع الرأس جمرها # كما أبرق الغيم الجهام وأرعدا\n",
      "ووافى أباها غاديا وهو حامل # حديدا طليق الشفرتين محددا\n",
      "وقال له يا مذبلا زهر الصبا # ويا جاعلا ماء الشبيبة أركدا\n",
      "أعد لي سلمى أين سلمى إلم تكن # تفدى بأرواح لكنت لها الفدى\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "\n",
    "instructions = f'generate {test_dataset[i][\"count\"]} verses in Arabic using the following verse as a starting point'\n",
    "input = test_dataset[i][\"input\"]\n",
    "output = '' \n",
    "text = f\"Instruction: {instructions}\\nInput: {input}\\nOutput: {output}\"\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "result = pipe(text)  #, temperature=0.7\n",
    "print(text)\n",
    "print()\n",
    "print(result[0]['generated_text'])\n",
    "print()\n",
    "print(f'the original output\\n{test_dataset[i][\"outputPoem\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84726d9a-d865-469c-b67e-16a93b7ad595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: لولا مغالبة الشجون لخاطري # لنظمت فيك يتيمة الأزمان\n",
      "Output: \n",
      "\n",
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: لولا مغالبة الشجون لخاطري # لنظمت فيك يتيمة الأزمان\n",
      "Output:  فكأنها في كل يوم منشأة # مني بغيرها على الإحسان\n",
      "فإذا هممت بمدحك المولى الذي # لم يرضه من أمد الدنيا مكان\n",
      "فكأنه لما علا فوق السما # في المجد أرسى من قواعد ركنان\n",
      "وإذا أتيتك في البلاغ\n",
      "\n",
      "the original output\n",
      "وأنا الذي أرثي الشموس إذا هوت # فتعود سيرتها إلى الدوران\n",
      "قد كنت تهتف في الورى بقصائدي # وتجل فوق النيرات مكاني\n",
      "ماذا دهاني يوم بنت فعقني # فيك القريض وخانني إمكاني\n",
      "هون عليك فلا شمات بميت # إن المنية غاية الإنسان\n"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "\n",
    "instructions = f'generate {test_dataset[i][\"count\"]} verses in Arabic using the following verse as a starting point'\n",
    "input = test_dataset[i][\"input\"]\n",
    "output = '' \n",
    "text = f\"Instruction: {instructions}\\nInput: {input}\\nOutput: {output}\"\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "result = pipe(text)  #, temperature=0.7\n",
    "print(text)\n",
    "print()\n",
    "print(result[0]['generated_text'])\n",
    "print()\n",
    "print(f'the original output\\n{test_dataset[i][\"outputPoem\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "352df7b2-d170-49cc-8013-3fa73a745580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: وأطلق رمحه فمضى # وهكطور انحنى حذرا\n",
      "Output: \n",
      "\n",
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: وأطلق رمحه فمضى # وهكطور انحنى حذرا\n",
      "Output:  وغادر الموت في ثياب # ن الموت فوق السهام\n",
      "ثم قال هكطور يرنو # ألا يا قوما احذروا\n",
      "وأقسمت بالهوى أن # لا أستطيع له قساما\n",
      "وأيقن أن يديه # يأتيها أينما حيا\n",
      "فيا قوم لا ترهبوا\n",
      "\n",
      "the original output\n",
      "فجاوز رأسه للأر # ض لا ينتابه ضرر\n",
      "ولكن بادرت فالا # س تنزعه على عجل\n",
      "وترجعه لأخي # ل وعن هكطور تستتر\n",
      "فصاح فتى الطراود # قد شططت وتدعي زورا\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "\n",
    "instructions = f'generate {test_dataset[i][\"count\"]} verses in Arabic using the following verse as a starting point'\n",
    "input = test_dataset[i][\"input\"]\n",
    "output = '' \n",
    "text = f\"Instruction: {instructions}\\nInput: {input}\\nOutput: {output}\"\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "result = pipe(text)  #, temperature=0.7\n",
    "print(text)\n",
    "print()\n",
    "print(result[0]['generated_text'])\n",
    "print()\n",
    "print(f'the original output\\n{test_dataset[i][\"outputPoem\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e101a931-41c8-4fbf-9899-58d3cbcc30a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: generate 3 verses in Arabic using the following verse as a starting point\n",
      "Input: شب الهوى شبة نيران # والفجر قد فجر أجفاني\n",
      "Output: \n",
      "\n",
      "Instruction: generate 3 verses in Arabic using the following verse as a starting point\n",
      "Input: شب الهوى شبة نيران # والفجر قد فجر أجفاني\n",
      "Output:  # \n",
      "عيناك في عين الغرام #  # \n",
      "\n",
      "the original output\n",
      "ما فعل الشمر على كفره # ما فعلت أجفان شمران\n",
      "لو لم يكن ثناه في حسنه # أخوه ما كان له ثان\n"
     ]
    }
   ],
   "source": [
    "i = 6\n",
    "\n",
    "instructions = f'generate {test_dataset[i][\"count\"]} verses in Arabic using the following verse as a starting point'\n",
    "input = test_dataset[i][\"input\"]\n",
    "output = '' \n",
    "text = f\"Instruction: {instructions}\\nInput: {input}\\nOutput: {output}\"\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "result = pipe(text)  #, temperature=0.7\n",
    "print(text)\n",
    "print()\n",
    "print(result[0]['generated_text'])\n",
    "print()\n",
    "print(f'the original output\\n{test_dataset[i][\"outputPoem\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a96c911-339a-40ea-a43a-450cae037ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: فغلق أبواب عنوة # وشيد أركان الخنا والمأثم\n",
      "Output: \n",
      "\n",
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: فغلق أبواب عنوة # وشيد أركان الخنا والمأثم\n",
      "Output:  فما زال يغشى القلوب بالظلم # \n",
      "ويمحو عن الحقائق كل نور # \n",
      "فلا يبعد اللهه مني سجنه # \n",
      "ولا يبعد اللهه مني سجنه #  ويشهدني الحق في الحشر والقسم  5 5 5 5 5 5 5 5 5 5 5\n",
      "\n",
      "the original output\n",
      "وأضحى على حب المفاسد عاكفا # فتبا لهذا من\n",
      "لقد عامل بالجور والجفا # ورش بالشقا والجرائم\n",
      "ولم يتبع في سنة # على جهله أحيا رسوم المعالم\n",
      "وأنسى بما أبدى شجاعة عنتر # وإقدام عمرو مع سماحة حاتم\n"
     ]
    }
   ],
   "source": [
    "i = 7\n",
    "\n",
    "instructions = f'generate {test_dataset[i][\"count\"]} verses in Arabic using the following verse as a starting point'\n",
    "input = test_dataset[i][\"input\"]\n",
    "output = '' \n",
    "text = f\"Instruction: {instructions}\\nInput: {input}\\nOutput: {output}\"\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "result = pipe(text)  #, temperature=0.7\n",
    "print(text)\n",
    "print()\n",
    "print(result[0]['generated_text'])\n",
    "print()\n",
    "print(f'the original output\\n{test_dataset[i][\"outputPoem\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54e961cf-a6db-4722-9bb0-7f521e5ee738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: مسحت قذى الدنيا يداك وإنما # كانت على الأيام مسحة أرمد\n",
      "Output: \n",
      "\n",
      "Instruction: generate 5 verses in Arabic using the following verse as a starting point\n",
      "Input: مسحت قذى الدنيا يداك وإنما # كانت على الأيام مسحة أرمد\n",
      "Output:  أين الألى قد كان منهم من يرى # فينا ويسمع من نداه ويجتدي\n",
      "أين الذين إذا التمست ركائب # كنا نرجي أن يصادفوك من اليد\n",
      "أين الذين إذا أتت خطبة # ألقى الكلام إليك غير مشدد\n",
      "أين الذين إذا جئنا بالشك\n",
      "\n",
      "the original output\n",
      "نالت بنو عبد السلام بك المدى # من كل سابقة وعز سرمد\n",
      "ضربوا بسيفك هام كل ملمة # سيف عن المعروف ليس بمغمد\n",
      "ورموا بسهمك عن قسي إصابة # غرض الكمال فكان أي مسدد\n",
      "القائدين الخيل تعثر بالطلى # عثر الرياح بكل طود أقود\n"
     ]
    }
   ],
   "source": [
    "i = 8\n",
    "\n",
    "instructions = f'generate {test_dataset[i][\"count\"]} verses in Arabic using the following verse as a starting point'\n",
    "input = test_dataset[i][\"input\"]\n",
    "output = '' \n",
    "text = f\"Instruction: {instructions}\\nInput: {input}\\nOutput: {output}\"\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "result = pipe(text)  #, temperature=0.7\n",
    "print(text)\n",
    "print()\n",
    "print(result[0]['generated_text'])\n",
    "print()\n",
    "print(f'the original output\\n{test_dataset[i][\"outputPoem\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb54bc-cf36-4243-8a63-13643383ed14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
